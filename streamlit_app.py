import streamlit as st
import pandas as pd
import zipfile
import requests
from bs4 import BeautifulSoup
from io import BytesIO
from typing import List

# ì´ë¯¸ì§€ ì••ì¶• ë‹¤ìš´ë¡œë“œ
def download_images_as_zip(image_urls: List[str], prefix="ì´ë¯¸ì§€") -> BytesIO:
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for i, url in enumerate(image_urls):
            try:
                response = requests.get(url)
                response.raise_for_status()
                zipf.writestr(f"{prefix}_{i+1}.jpg", response.content)
            except:
                continue
    zip_buffer.seek(0)
    return zip_buffer

# ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ í•¨ìˆ˜
def get_product_info(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0"}
        res = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, "html.parser")

        product_name = soup.select_one("meta[property='og:title']")
        product_name = product_name['content'].strip() if product_name else "ì œëª© ì—†ìŒ"

        image_tag = soup.select_one("meta[property='og:image']")
        image_url = image_tag['content'] if image_tag else ""

        price_tag = soup.select_one(".price-now, .product-price, .price")
        price = price_tag.text.strip() if price_tag else ""

        desc_tag = soup.select_one(".product-detail")
        description = desc_tag.get_text(strip=True) if desc_tag else ""

        detail_imgs = soup.select("#tabPageDetail img") or soup.select(".product-detail img")
        detail_image_urls = []
        for img in detail_imgs:
            src = img.get('src')
            if src:
                if src.startswith('//'):
                    src = 'https:' + src
                elif src.startswith('/'):
                    src = 'https://www.domeggook.com' + src
                detail_image_urls.append(src)

        return {
            "ìƒí’ˆëª…": product_name,
            "ê°€ê²©": price,
            "ëŒ€í‘œì´ë¯¸ì§€": image_url,
            "ìƒì„¸ì„¤ëª…": description,
            "ìƒì„¸ì´ë¯¸ì§€": detail_image_urls,
            "ìƒí’ˆURL": url
        }
    except Exception as e:
        return {"ìƒí’ˆëª…": f"âŒ ì˜¤ë¥˜: {e}", "ìƒí’ˆURL": url}

# Streamlit UI
st.title("ğŸ§¼ ë„ë§¤ê¾¹ ê³µê°œ ìƒí’ˆ í¬ë¡¤ëŸ¬ (Selenium ì—†ì´)")

urls_input = st.text_area("ğŸ“¥ ë„ë§¤ê¾¹ ìƒí’ˆ URL ì…ë ¥ (í•œ ì¤„ì— í•˜ë‚˜ì”©)")

if st.button("ğŸš€ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘"):
    urls = [u.strip() for u in urls_input.strip().splitlines() if u.strip()]
    if not urls:
        st.warning("URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        results = []
        all_images = []

        with st.spinner("í¬ë¡¤ë§ ì¤‘..."):
            for url in urls:
                data = get_product_info(url)
                all_images.extend([data["ëŒ€í‘œì´ë¯¸ì§€"]] + data.get("ìƒì„¸ì´ë¯¸ì§€", []))
                data["ìƒì„¸ì´ë¯¸ì§€"] = ";".join(data.get("ìƒì„¸ì´ë¯¸ì§€", []))
                results.append(data)

        df = pd.DataFrame(results)
        st.success(f"{len(df)}ê°œ ìƒí’ˆ ìˆ˜ì§‘ ì™„ë£Œ!")
        st.dataframe(df)

        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
        excel_buffer = BytesIO()
        df.to_excel(excel_buffer, index=False)
        excel_buffer.seek(0)
        st.download_button("ğŸ“„ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", data=excel_buffer, file_name="domeggook_products.xlsx")

        # ì´ë¯¸ì§€ ZIP
        if all_images:
            zip_file = download_images_as_zip(all_images)
            st.download_button("ğŸ–¼ ì´ë¯¸ì§€ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_file, file_name="images.zip")
