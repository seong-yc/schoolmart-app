# streamlit_app.py
import streamlit as st
import pandas as pd
import zipfile
import requests
from io import BytesIO
from bs4 import BeautifulSoup
from typing import List, Dict
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.common.keys import Keys
from selenium.webdriver.chrome.service import Service
from webdriver_manager.chrome import ChromeDriverManager
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
import os
import time
from dotenv import load_dotenv

# --------- í™˜ê²½ë³€ìˆ˜ ë¡œë“œ ---------
load_dotenv()
DOMEGGOOK_ID = os.getenv("DOMEGGOOK_ID")
DOMEGGOOK_PW = os.getenv("DOMEGGOOK_PW")

# --------- í¬ë¡¤ë§ í•¨ìˆ˜ ---------
def get_product_info_from_url(url: str) -> Dict[str, str]:
    try:
        # Selenium ì„¤ì •
        options = Options()
        # options.add_argument('--headless')  # ë””ë²„ê¹… ì‹œ ì£¼ì„ ì²˜ë¦¬í•˜ë©´ í¬ë¡¬ ì°½ì´ ëœ¸
        options.add_argument('--disable-gpu')
        options.add_argument('--no-sandbox')
        options.add_argument('--window-size=1920x1080')  # ì•ˆì •ì ì¸ ë¡œë”©ì„ ìœ„í•´ ê¶Œì¥
        driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

        # ë¡œê·¸ì¸ ì²˜ë¦¬
        driver.get("https://domeggook.com/login")
        WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, "user_id")))
        driver.find_element(By.ID, "user_id").send_keys(DOMEGGOOK_ID)
        driver.find_element(By.ID, "user_pw").send_keys(DOMEGGOOK_PW + Keys.RETURN)
        time.sleep(2)

        # ìƒí’ˆ í˜ì´ì§€ ì ‘ì†
        driver.get(url)
        time.sleep(2)
        html = driver.page_source
        soup = BeautifulSoup(html, "html.parser")

        def extract_text(selector, attr=None):
            tag = soup.select_one(selector)
            if tag:
                return tag.get(attr) if attr else tag.get_text(strip=True)
            return "N/A"

        product_info = {
            "ìƒí’ˆëª…": extract_text("meta[property='og:title']", attr="content"),
            "ëŒ€í‘œ ì´ë¯¸ì§€ URL": extract_text("meta[property='og:image']", attr="content"),
            "ìƒí’ˆì„¤ëª… HTML": str(soup.find("div", {"id": "tabPageDetail"})) or "N/A",
            "ê³µê¸‰ì‚¬ëª…": "N/A",
            "ì›ì‚°ì§€": "N/A",
            "ë°°ì†¡ë°©ë²•": "N/A",
            "ë°°ì†¡ê¸ˆì•¡": "N/A",
            "ìˆ˜ëŸ‰ê¸°ì¤€": "N/A",
            "ë‹¨ê°€": "N/A",
            "ìƒí’ˆURL": url,
            "ì˜µì…˜ëª©ë¡": []
        }

        # í…Œì´ë¸” ì •ë³´ ì¶”ì¶œ
        tables = soup.find_all("table")
        for table in tables:
            for row in table.find_all("tr"):
                cells = row.find_all(["th", "td"])
                if len(cells) >= 2:
                    key = cells[0].get_text(strip=True)
                    value = cells[1].get_text(strip=True)
                    if "ê³µê¸‰ì‚¬ëª…" in key:
                        product_info["ê³µê¸‰ì‚¬ëª…"] = value
                    elif "ì›ì‚°ì§€" in key:
                        product_info["ì›ì‚°ì§€"] = value
                    elif "ë°°ì†¡ë°©ë²•" in key:
                        product_info["ë°°ì†¡ë°©ë²•"] = value
                    elif "ë°°ì†¡ê¸ˆì•¡" in key:
                        product_info["ë°°ì†¡ê¸ˆì•¡"] = value
                    elif "ìˆ˜ëŸ‰" in key:
                        product_info["ìˆ˜ëŸ‰ê¸°ì¤€"] = key
                        product_info["ë‹¨ê°€"] = value

        # ì˜µì…˜ ì •ë³´ ì¶”ì¶œ
        option_table = soup.find("table", {"class": "table_item_option"})
        if option_table:
            for row in option_table.find_all("tr"):
                cells = row.find_all("td")
                if len(cells) >= 2:
                    option_name = cells[0].get_text(strip=True)
                    option_price = cells[1].get_text(strip=True)
                    product_info["ì˜µì…˜ëª©ë¡"].append({"ì˜µì…˜ëª…": option_name, "ê°€ê²©": option_price})

        # ìƒì„¸ ì´ë¯¸ì§€ ìˆ˜ì§‘
        img_tags = soup.select("#tabPageDetail img")
        detail_imgs = [img['src'] for img in img_tags if img.get('src')]
        product_info["ìƒì„¸ì´ë¯¸ì§€ URL"] = detail_imgs

        driver.quit()
        return product_info
    except Exception as e:
        return {"ìƒí’ˆëª…": f"ERROR: {e}", "ìƒí’ˆURL": url}

# --------- ì´ë¯¸ì§€ ZIP ---------
def download_images_as_zip(image_urls: List[str], prefix="ëŒ€í‘œì´ë¯¸ì§€") -> BytesIO:
    zip_buffer = BytesIO()
    with zipfile.ZipFile(zip_buffer, "w") as zipf:
        for i, url in enumerate(image_urls):
            try:
                response = requests.get(url)
                zipf.writestr(f"{prefix}_{i+1}.jpg", response.content)
            except:
                continue
    zip_buffer.seek(0)
    return zip_buffer

# --------- Streamlit UI ---------
st.title("ğŸ“¦ ë„ë§¤ê¾¹ ìƒí’ˆ ì •ë³´ í¬ë¡¤ëŸ¬")

urls_input = st.text_area("ë„ë§¤ê¾¹ ìƒí’ˆ URLì„ ì¤„ë°”ê¿ˆìœ¼ë¡œ ì…ë ¥í•˜ì„¸ìš”:")

if st.button("í¬ë¡¤ë§ ì‹œì‘"):
    urls = [line.strip() for line in urls_input.strip().splitlines() if line.strip()]
    if not urls:
        st.warning("URLì„ í•˜ë‚˜ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        results = []
        main_images = []
        detail_images = []
        with st.spinner("ìƒí’ˆ ì •ë³´ë¥¼ ìˆ˜ì§‘ ì¤‘ì…ë‹ˆë‹¤..."):
            for url in urls:
                data = get_product_info_from_url(url)
                # ì˜µì…˜ì´ ìˆì„ ê²½ìš° ì˜µì…˜ë§ˆë‹¤ í–‰ ìƒì„±
                if data.get("ì˜µì…˜ëª©ë¡"):
                    for opt in data["ì˜µì…˜ëª©ë¡"]:
                        row = data.copy()
                        row.update(opt)
                        del row["ì˜µì…˜ëª©ë¡"]
                        results.append(row)
                else:
                    if "ì˜µì…˜ëª©ë¡" in data:
                        del data["ì˜µì…˜ëª©ë¡"]
                    results.append(data)

                if data.get("ëŒ€í‘œ ì´ë¯¸ì§€ URL", "N/A") != "N/A":
                    main_images.append(data["ëŒ€í‘œ ì´ë¯¸ì§€ URL"])
                if data.get("ìƒì„¸ì´ë¯¸ì§€ URL"):
                    detail_images.extend(data["ìƒì„¸ì´ë¯¸ì§€ URL"])

        df = pd.DataFrame(results)
        st.success("í¬ë¡¤ë§ ì™„ë£Œ!")
        st.dataframe(df.drop(columns=["ìƒì„¸ì´ë¯¸ì§€ URL", "ìƒí’ˆì„¤ëª… HTML"], errors="ignore"))

        # ì—‘ì…€ ë‹¤ìš´ë¡œë“œ
        excel_buffer = BytesIO()
        df.to_excel(excel_buffer, index=False)
        excel_buffer.seek(0)
        st.download_button("ğŸ“¥ ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", excel_buffer, file_name="ìƒí’ˆì •ë³´.xlsx")

        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        if main_images:
            zip_main = download_images_as_zip(main_images, "ëŒ€í‘œì´ë¯¸ì§€")
            st.download_button("ğŸ“¸ ëŒ€í‘œ ì´ë¯¸ì§€ ZIP", zip_main, file_name="ëŒ€í‘œì´ë¯¸ì§€.zip")

        if detail_images:
            zip_detail = download_images_as_zip(detail_images, "ìƒì„¸ì´ë¯¸ì§€")
            st.download_button("ğŸ–¼ï¸ ìƒì„¸ ì´ë¯¸ì§€ ZIP", zip_detail, file_name="ìƒì„¸ì´ë¯¸ì§€.zip")
